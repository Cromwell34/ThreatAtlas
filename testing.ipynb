{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing event tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd \n",
    "import string\n",
    "import event_tools as events\n",
    "import ipywidgets as widgets\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press button to get top N countries\n",
    "## Global homepage \n",
    "# Map GDELT scores and mention frequencies\n",
    "# Visualize orgs and individual counts + network* + Phrases \n",
    "# Get select news based on phrase and entity counts \n",
    "# top_n_countries = events.top_n_bar_chart()\n",
    "\n",
    "## Country breakdowns \n",
    "# Get time series from GDELT + ACLED \n",
    "# Visualize orgs and individual counts + network* + Phrases \n",
    "# Generate news feed: GDELT + RSS \n",
    "\n",
    "\n",
    "t_str1 = widgets.FloatText( description='Strain in %:', value='3' )\n",
    "b_cs   = widgets.Button( description='Compute Stress' )\n",
    "t_str2 = widgets.Label(value='Waiting' )\n",
    "\n",
    "vb=widgets.VBox([t_str1,b_cs,t_str2])\n",
    "\n",
    "def on_click_compute_stress(b):\n",
    "    t_str2.value= events.get_content('')\n",
    "\n",
    "b_cs.on_click(on_click_compute_stress)\n",
    "\n",
    "display(vb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_ents1(ents):\n",
    "    flat_ents = []\n",
    "    for ent in ents:\n",
    "        flat_ents = flat_ents + ent[1]\n",
    "\n",
    "    return flat_ents\n",
    "\n",
    "\n",
    "def new_count(field,frame):\n",
    "    indexed = list(zip(list(range(len(frame[field].tolist()))),frame[field].tolist()))\n",
    "    all_ = flat_ents1(indexed)\n",
    "    counted_ = {i:all_.count(i) for i in all_}\n",
    "    counted = sorted(counted_.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return counted\n",
    "\n",
    "\n",
    "\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "def get_summaries(headlines,df):\n",
    "    summaries = []\n",
    "    for headline in headlines[0]:\n",
    "        summaries.append(df.loc[df[\"Title\"] == headline]['Summary'].to_list())\n",
    "\n",
    "    return flatten_list(summaries)\n",
    "\n",
    "\n",
    "def top_n_bar_chart(data, n,var_name,vertical):\n",
    "    if vertical == True:\n",
    "        y = [k[0] for k in data[1:n]]\n",
    "        x = [k[1] for k in data[1:n]]\n",
    "        data = [go.Bar(x=x, y=y,orientation='h')]\n",
    "        layout = go.Layout(title=f\"Top {n} \"+var_name,template=\"plotly_dark\")\n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        fig.show()\n",
    "\n",
    "    else:\n",
    "        x = [k[0] for k in data[1:n]]\n",
    "        y = [k[1] for k in data[1:n]]\n",
    "        data = [go.Bar(x=x, y=y)]\n",
    "        layout = go.Layout(title=f\"Top {n} \"+var_name,template=\"plotly_dark\" )\n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "def country_headlines(country, df):\n",
    "    headlines = df.loc[df['country'] == country]['headlines']\n",
    "\n",
    "    return headlines\n",
    "\n",
    "def extract_ngrams(article, n):\n",
    "    # Tokenize the article into words\n",
    "    tokens = nltk.word_tokenize(article)\n",
    "    \n",
    "    # Generate the N-grams\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    \n",
    "    # Count the N-grams\n",
    "    n_gram_counts = Counter(n_grams)\n",
    "    \n",
    "    return n_gram_counts\n",
    "\n",
    "\n",
    "def clean_stopwords(article):\n",
    "    # Tokenize the article into words\n",
    "    tokens = word_tokenize(article)\n",
    "    \n",
    "    # Get the English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Filter out the stopwords\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Join the filtered tokens back into a string\n",
    "    cleaned_article = ' '.join(filtered_tokens)\n",
    "    \n",
    "    \n",
    "    return cleaned_article\n",
    "\n",
    "\n",
    "def aggregate_ngrams(articles, n):\n",
    "\n",
    "    ngrams = []\n",
    "    for article in articles:\n",
    "        a = clean_stopwords(article).translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        for k in extract_ngrams(a,n).keys():\n",
    "            ngrams.append(k)\n",
    "\n",
    "    return Counter(ngrams)\n",
    "\n",
    "\n",
    "def country_ngrams(country,master, n):\n",
    "    summaries = get_summaries(country,master)\n",
    "    n_gram_counts = dict(sorted(aggregate_ngrams(summaries,n).items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "    return n_gram_counts\n",
    "\n",
    "def get_entities(headlines, df, type_):\n",
    "    ents_nested = []\n",
    "    ents = []\n",
    "    \n",
    "    for headline in headlines[0]:\n",
    "        ents_nested.append(df.loc[df[\"Title\"] == headline][type_].to_list())\n",
    "    \n",
    "    for li in ents_nested: \n",
    "        for li2 in li:\n",
    "            for e in li2: \n",
    "                ents.append(e)\n",
    "\n",
    "    return (sorted(Counter(ents).items(),key=lambda item: item[1],reverse=True),ents_nested)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_set = pd.read_json('aggregated_dataNewTest2.json')\n",
    "test_master = pd.read_json('output.json',encoding='utf-8')\n",
    "\n",
    "all_countries = list(zip(test_set['country'].to_list(),test_set['mentions'].to_list()))\n",
    "counted_countries = sorted(all_countries, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "top_n_bar_chart(counted_countries,25,\"Associated countries\",vertical=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_ = \"Afghanistan\"\n",
    "k = 25\n",
    "n = 3\n",
    "\n",
    "country = country_headlines(country_ ,test_set).to_list()\n",
    "summaries = get_summaries(country,test_master)\n",
    "\n",
    "\n",
    "n_gram_counts = dict(sorted(aggregate_ngrams(summaries,n).items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "individuals = get_entities(country,test_master,'Associated Individuals')\n",
    "orgs = get_entities(country,test_master,'Associated Organizations')\n",
    "\n",
    "top_n_bar_chart(individuals[0],k,\"Associated individuals\",vertical=True)\n",
    "top_n_bar_chart(orgs[0],k,\"Associated Organizations\",vertical=True)\n",
    "\n",
    "for a in (n_gram_counts.items()):\n",
    "    if a[1] > 1:\n",
    "        print(\" \".join(a[0])+ \": \"+str(a[1]))\n",
    "\n",
    "for a in country[0]:\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
